{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (pipeline.py, line 7)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[1;36m(most recent call last)\u001b[0m:\n",
      "  File \u001b[0;32m\"C:\\Users\\kyle\\Anaconda2\\envs\\carnd-term1\\lib\\site-packages\\IPython\\core\\interactiveshell.py\"\u001b[0m, line \u001b[0;32m2862\u001b[0m, in \u001b[0;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-1-ebe794cff55c>\"\u001b[1;36m, line \u001b[1;32m7\u001b[1;36m, in \u001b[1;35m<module>\u001b[1;36m\u001b[0m\n\u001b[1;33m    from pipeline import pipeline\u001b[0m\n",
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\kyle\\Desktop\\Summer2017\\SelfDriving\\self-driving\\CarND-Advanced-Lane-Lines\\pipeline.py\"\u001b[1;36m, line \u001b[1;32m7\u001b[0m\n\u001b[1;33m    getSobelY, getSobelDirection, getSatBinary, combineBinary, windSlide, usePrevSlide\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import glob\n",
    "from helper import warp, getSobelBinaryX, getSobelBinaryY, getSobelX, getSobelY, getSobelDirection, getSatBinary, combineBinary, windSlide, usePrevSlide\n",
    "from pipeline import pipeline\n",
    "\n",
    "%matplotlib inline\n",
    "%matplotlib qt\n",
    "%qtconsole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "images = glob.glob('camera_cal/calibration*.jpg')\n",
    "\n",
    "# Arrays to store object points and image points from all the images\n",
    "\n",
    "objpoints = [] # 3D points in real world space\n",
    "imgpoints = [] # 2D points in image plane\n",
    "\n",
    "objp = np.zeros((6*9,3), np.float32)\n",
    "objp[:,:2] = np.mgrid[0:9, 0:6].T.reshape(-1, 2) # x, y coordinates\n",
    "\n",
    "for fname in images:\n",
    "    #read in each image\n",
    "    img = mpimg.imread(fname)\n",
    "    \n",
    "    # convert image to grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "    # find the chessboard corners\n",
    "    ret, corners = cv2.findChessboardCorners(gray, (9,6), None)\n",
    "    # If corners are found, add object points, image points\n",
    "    if ret == True:\n",
    "        imgpoints.append(corners)\n",
    "        objpoints.append(objp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = 'camera_cal/calibration2.jpg'\n",
    "img = mpimg.imread(fname)\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "ret, corners = cv2.findChessboardCorners(gray, (9,6), None)\n",
    "img = cv2.drawChessboardCorners(img, (9,6), corners, ret)\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calibrate(img, objpoints, imgpoints):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, gray.shape[::-1], None, None)\n",
    "    undist = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "    return undist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save a calibrated image for final report\n",
    "import scipy.misc\n",
    "fname = 'test_images/test1.jpg'\n",
    "img = mpimg.imread(fname)\n",
    "new_img = calibrate(img, objpoints, imgpoints)\n",
    "scipy.misc.imsave('output_images/test1.jpg', new_img)\n",
    "#f, axes = plt.subplots(1, 2, figsize=(20,10))\n",
    "#axes[0].imshow(img)\n",
    "#axes[1].imshow(new_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perspective Warp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thresholding Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = 'test_images/test4.jpg'\n",
    "img = mpimg.imread(fname)\n",
    "img = calibrate(img, objpoints, imgpoints)\n",
    "img_size = (img.shape[1], img.shape[0])\n",
    "# Convert to HLS color space and separate the S channel\n",
    "hls = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "s_channel = hls[:,:,2]\n",
    "l_channel = hls[:,:,1]\n",
    "h_channel = hls[:,:,0]\n",
    "# Grayscale image\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "#gray = cv2.equalizeHist(gray)\n",
    "# Warp Image\n",
    "\n",
    "# Threshold x gradient\n",
    "sxbinary = getSobelBinaryX(gray, sobel_kernel = 15, thresh_min = 210, thresh_max=255)\n",
    "\n",
    "# Threshold y gradient\n",
    "sybinary = getSobelBinaryY(gray, sobel_kernel = 15, thresh_min = 245, thresh_max=255)\n",
    "\n",
    "# Threshold direction gradient\n",
    "dirbinary = getSobelDirection(gray, sobel_kernel = 3, thresh_min = np.pi/2-0.3, thresh_max=np.pi/2-0.2)\n",
    "\n",
    "# Threshold color channel\n",
    "s_binary = getSatBinary(s_channel, thresh_min = 140, thresh_max=255)\n",
    "s_binary = getSobelBinaryX(s_channel, sobel_kernel = 15, thresh_min = 235, thresh_max=255)\n",
    "\n",
    "# Stack each channel to view their individual contributions in green and blue respectively\n",
    "# This returns a stack of the two binary images, whose components you can see as different colors\n",
    "color_binary = warp(np.dstack(( np.zeros_like(sxbinary), s_binary, sxbinary)) * 255)\n",
    "\n",
    "# Combine the two binary thresholds\n",
    "#combined_binary = combineBinary\n",
    "\n",
    "# Plotting thresholded images\n",
    "\n",
    "f, axes = plt.subplots(2, 2, figsize=(20,10))\n",
    "axes[0,0].set_title('Gray')\n",
    "axes[0,0].imshow(gray, cmap='gray')\n",
    "\n",
    "#axes[0,1].set_title('Combined S channel and gradient thresholds')\n",
    "axes[0,1].set_title('S Channel')\n",
    "axes[0,1].imshow(s_channel, cmap='gray')\n",
    "\n",
    "axes[1,0].set_title('S binary')\n",
    "axes[1,0].imshow(s_binary, cmap='gray')\n",
    "\n",
    "binary_warped = np.zeros_like(sxbinary)\n",
    "binary_warped[(sxbinary == 1) | (s_binary == 1)] = 1\n",
    "binary_warped, minv = warp(s_binary)\n",
    "\n",
    "axes[1,1].set_title('Color')\n",
    "axes[1,1].imshow(binary_warped, cmap='gray')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import everything needed to edit/save/watch video clips\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_image(image):\n",
    "    # NOTE: The output you return should be a color image (3 channel) for processing video below\n",
    "    # TODO: put your pipeline here,\n",
    "    # you should return the final output (image where lines are drawn on lanes)\n",
    "    \n",
    "    return pipeline(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proj_video_out = 'project_video_output.mp4'\n",
    "## To speed up the testing process you may want to try your pipeline on a shorter subclip of the video\n",
    "## To do so add .subclip(start_second,end_second) to the end of the line below\n",
    "## Where start_second and end_second are integer values representing the start and end of the subclip\n",
    "## You may also uncomment the following line for a subclip of the first 5 seconds\n",
    "##clip1 = VideoFileClip(\"test_videos/solidWhiteRight.mp4\").subclip(0,5)\n",
    "clip1 = VideoFileClip(\"project_video.mp4\").subclip(38,41)\n",
    "white_clip = clip1.fl_image(process_image) #NOTE: this function expects color images!!\n",
    "%time white_clip.write_videofile(proj_video_out, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(proj_video_out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Line():\n",
    "    def __init__(self):\n",
    "        # was the line detected in the last iteration?\n",
    "        self.detected = False  \n",
    "        # x values of the last n fits of the line\n",
    "        self.recent_xfitted = [] \n",
    "        \n",
    "        self.left_fit = None\n",
    "        \n",
    "        self.right_fit = None\n",
    "        #average x values of the fitted line over the last n iterations\n",
    "        self.bestx = None     \n",
    "        #polynomial coefficients averaged over the last n iterations\n",
    "        self.best_fit = None  \n",
    "        #polynomial coefficients for the most recent fit\n",
    "        self.current_fit = [np.array([False])]  \n",
    "        #radius of curvature of the line in some units\n",
    "        self.left_curverad = None\n",
    "        self.right_curverad = None\n",
    "        #distance in meters of vehicle center from the line\n",
    "        self.line_base_pos = None \n",
    "        #difference in fit coefficients between last and new fits\n",
    "        self.diffs = np.array([0,0,0], dtype='float') \n",
    "        #x values for detected line pixels\n",
    "        self.allx = None  \n",
    "        #y values for detected line pixels\n",
    "        self.ally = None\n",
    "\n",
    "lanes = Line()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
